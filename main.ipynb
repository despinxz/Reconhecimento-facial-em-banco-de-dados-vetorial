{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fad5ac",
   "metadata": {},
   "source": [
    "## Instalação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df9451",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!powershell pip install \\\n",
    "            face_recognition \\\n",
    "            git+https://github.com/ageitgey/face_recognition_models \\\n",
    "            opencv-python \\\n",
    "            pillow \\\n",
    "            numpy \\\n",
    "            tqdm \\\n",
    "            qdrant-client \\\n",
    "            setuptools \\\n",
    "            ipywidgets \\\n",
    "            matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908e1a5",
   "metadata": {},
   "source": [
    "## Rodar Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03368e35",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!powershell docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b376062",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532f2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import face_recognition\n",
    "import face_recognition_models\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import Filter, SearchRequest\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f389a",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963724dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configura_ambiente(nome_colecao, tamanho_vetor):\n",
    "    # Conectando ao Qdrant local\n",
    "    client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "    # Cria a coleção se não existir\n",
    "    if nome_colecao not in [c.name for c in client.get_collections().collections]:\n",
    "        client.recreate_collection(\n",
    "            collection_name=nome_colecao,\n",
    "            vectors_config=VectorParams(size=tamanho_vetor, distance=Distance.COSINE),\n",
    "        )\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ae57e",
   "metadata": {},
   "source": [
    "## Código para processar imagens do lfw_funneled e inserir na coleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0e7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_imagens(dir):\n",
    "    '''\n",
    "    Função usada para processar todos os diretórios e fotos dentro de lfw_funneled.\n",
    "\n",
    "    Args:\n",
    "        dir: Nome do diretório que contém as fotos.\n",
    "    \n",
    "    Returns:\n",
    "        return: Vetor com as imagens processas em formato de PointStruct para serem inseridas na coleção.\n",
    "    '''\n",
    "    pontos = []\n",
    "    diretorios = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "\n",
    "    for pessoa in tqdm(diretorios, desc=f\"Processando imagens...\"):\n",
    "        dir_pessoa = os.path.join(dir, pessoa)\n",
    "\n",
    "        for nome_arq in os.listdir(dir_pessoa):\n",
    "            if not nome_arq.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            caminho_imagem = os.path.join(dir_pessoa, nome_arq)\n",
    "            imagem = face_recognition.load_image_file(caminho_imagem)\n",
    "            embeddings = face_recognition.face_encodings(imagem)\n",
    "\n",
    "            if len(embeddings) == 0:\n",
    "                continue    # Pula se não encontrar rostos\n",
    "\n",
    "            embedding_pessoa = embeddings[0]    # Presume que o primeiro e único rosto encontrado será da pessoa nomeada\n",
    "\n",
    "            id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "            # Cria estrutura de ponto para inserir na coleção\n",
    "            pontos.append(\n",
    "                PointStruct(\n",
    "                    id=id_ponto,\n",
    "                    vector=embedding_pessoa.tolist(),\n",
    "                    payload={\"nome\": pessoa, \"arquivo\": caminho_imagem}\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    return pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c9956",
   "metadata": {},
   "source": [
    "Código para processar apenas diretórios com mais de 3 imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_imagens_reduzido(dir, num_min_fotos=5, num_max_fotos):\n",
    "    '''\n",
    "    Função usada para processar todos os diretórios e fotos dentro de lfw_funneled.\n",
    "\n",
    "    Args:\n",
    "        dir: Nome do diretório que contém as fotos.\n",
    "        num_min_fotos: Número mínimo de fotos que o diretório deve conter para ser processado.\n",
    "        num_max_fotos: Número máximo de fotos que o diretório deve conter para ser processado.\n",
    "\n",
    "    Returns:\n",
    "        return: Vetor com as imagens processas em formato de PointStruct para serem inseridas na coleção.\n",
    "    '''\n",
    "    pontos = []\n",
    "    todos_diretorios = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    diretorios_selecionados = []\n",
    "    for pessoa in todos_diretorios:\n",
    "        dir_pessoa = os.path.join(dir, pessoa)\n",
    "        if len(os.listdir(dir_pessoa)) >= num_min_fotos and len(os.listdir(dir_pessoa)) <= num_max_fotos:\n",
    "            diretorios_selecionados.append(dir_pessoa)\n",
    "\n",
    "    for pessoa in tqdm(diretorios_selecionados, desc=f\"Processando imagens...\"):\n",
    "        for nome_arq in os.listdir(pessoa):\n",
    "            if not nome_arq.endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            caminho_imagem = os.path.join(pessoa, nome_arq)\n",
    "            imagem = face_recognition.load_image_file(caminho_imagem)\n",
    "            embeddings = face_recognition.face_encodings(imagem)\n",
    "\n",
    "            if len(embeddings) == 0:\n",
    "                continue    # Pula se não encontrar rostos\n",
    "\n",
    "            embedding_pessoa = embeddings[0]    # Presume que o primeiro e único rosto encontrado será da pessoa nomeada\n",
    "\n",
    "            id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "            # Cria estrutura de ponto para inserir na coleção\n",
    "            pontos.append(\n",
    "                PointStruct(\n",
    "                    id=id_ponto,\n",
    "                    vector=embedding_pessoa.tolist(),\n",
    "                    payload={\"nome\": pessoa.split('\\\\')[1], \"arquivo\": caminho_imagem}\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    return pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a04cb8",
   "metadata": {},
   "source": [
    "## Códigos para o CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a0c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_imagem(client, nome_pessoa, filename):\n",
    "    '''\n",
    "    Função usada para processar e inserir uma imagem de uma pessoa na coleção.\n",
    "\n",
    "    Args:\n",
    "        filename: Caminho da imagem.\n",
    "    \n",
    "    Returns:\n",
    "        return: \n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7eeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletar_imagem(client, nome_pessoa):\n",
    "    '''\n",
    "    Função usada para deletar as fotos de uma pessoa na coleção.\n",
    "\n",
    "    Args:\n",
    "        nome_pessoa: Nome da pessoa a ser deletada.\n",
    "    \n",
    "    Returns:\n",
    "        return: \n",
    "    '''\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660052e",
   "metadata": {},
   "source": [
    "## Códigos para processamento de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea89455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_rostos_similares(client, colecao: str, arquivo: str, top_k: int = 5):\n",
    "    '''\n",
    "    Função usada para buscar os rostos mais similares à imagem passada como parâmetro.\n",
    "\n",
    "    Args:\n",
    "        colecao: Nome da coleção onde as imagens serão buscadas.\n",
    "        arquivo: Caminho da imagem selecionada como parâmetro.\n",
    "        top_k: Número de imagens semelhantes a serem retornadas.\n",
    "    \n",
    "    Returns:\n",
    "        return: Vetor com as imagens mais semelhantes.\n",
    "    '''\n",
    "\n",
    "    imagem = face_recognition.load_image_file(arquivo)\n",
    "    embedding = face_recognition.face_encodings(imagem)[0]\n",
    "    resultado = client.search(collection_name=colecao, \n",
    "                              query_vector=embedding.tolist(), \n",
    "                              limit=top_k)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d230aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_resultados_similares(client, colecao: str, arquivo: str, top_k: int = 5):\n",
    "    '''\n",
    "    Exibe as imagens mais semelhantes à imagem fornecida, com nome da pessoa e scores de similaridade.\n",
    "\n",
    "    Args:\n",
    "        client: Cliente Qdrant.\n",
    "        colecao: Nome da coleção onde as imagens serão buscadas.\n",
    "        arquivo: Caminho da imagem selecionada como parâmetro.\n",
    "        top_k: Número de imagens semelhantes a serem exibidas.\n",
    "    '''\n",
    "\n",
    "    resultados = buscar_rostos_similares(client, colecao, arquivo, top_k)\n",
    "\n",
    "    # Carrega e exibe a imagem de entrada\n",
    "    imagem_consulta = mpimg.imread(arquivo)\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.subplot(1, top_k + 1, 1)\n",
    "    plt.imshow(imagem_consulta)\n",
    "    plt.title(\"Imagem Consulta\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Exibe as imagens semelhantes\n",
    "    for i, item in enumerate(resultados, start=2):\n",
    "        caminho_imagem = item.payload.get(\"arquivo\", \"Desconhecido\")\n",
    "        nome_pessoa = item.payload.get(\"nome\", \"Desconhecido\")\n",
    "        score = item.score\n",
    "\n",
    "        try:\n",
    "            img = mpimg.imread(caminho_imagem)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Arquivo não encontrado: {caminho_imagem}\")\n",
    "            continue\n",
    "\n",
    "        plt.subplot(1, top_k + 1, i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{nome_pessoa}\\nScore: {score:.2f}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c98c0",
   "metadata": {},
   "source": [
    "## Exemplo de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef18b5c",
   "metadata": {},
   "source": [
    "Configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a9bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = \"lfw_funneled\"\n",
    "nome_colecao = \"lfw_faces\"\n",
    "tamanho_vetor = 128     # Número de dimensões do embedding do face_recognition\n",
    "\n",
    "client = configura_ambiente(nome_colecao, tamanho_vetor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens...:  11%|█▏        | 18/158 [03:14<25:16, 10.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Processa imagens e insere no Qdrant\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pontos = \u001b[43mprocessa_imagens_reduzido\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiretorio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_min_fotos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pontos:\n\u001b[32m      4\u001b[39m     client.upsert(collection_name=nome_colecao, points=pontos)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mprocessa_imagens_reduzido\u001b[39m\u001b[34m(dir, num_min_fotos)\u001b[39m\n\u001b[32m     25\u001b[39m caminho_imagem = os.path.join(pessoa, nome_arq)\n\u001b[32m     26\u001b[39m imagem = face_recognition.load_image_file(caminho_imagem)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m embeddings = \u001b[43mface_recognition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embeddings) == \u001b[32m0\u001b[39m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m    \u001b[38;5;66;03m# Pula se não encontrar rostos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\Lib\\site-packages\\face_recognition\\api.py:214\u001b[39m, in \u001b[36mface_encodings\u001b[39m\u001b[34m(face_image, known_face_locations, num_jitters, model)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[33;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[32m    206\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m \u001b[33;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    213\u001b[39m raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Processa imagens e insere no Qdrant\n",
    "pontos = processa_imagens_reduzido(diretorio, num_min_fotos=5, num_max_fotos=7)\n",
    "if pontos:\n",
    "    client.upsert(collection_name=nome_colecao, points=pontos)\n",
    "    print(f\"Inseridos {len(pontos)} vetores na coleção '{nome_colecao}'\")\n",
    "else:\n",
    "    print(\"Nenhuma imagem válida foi processada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb063e",
   "metadata": {},
   "source": [
    "Teste de busca por similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_buscada = \"lfw_funneled\\\\Cate_Blanchett\\\\Cate_Blanchett_0001.jpg\"\n",
    "exibir_resultados_similares(client, nome_colecao, imagem_buscada, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a283d7",
   "metadata": {},
   "source": [
    "## Comando para deletar coleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6510dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(collection_name=nome_colecao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
