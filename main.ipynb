{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1bd469",
   "metadata": {},
   "source": [
    "# Instalação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bd40e36",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ageitgey/face_recognition_models\n",
      "  Cloning https://github.com/ageitgey/face_recognition_models to c:\\users\\despinxz\\appdata\\local\\temp\\pip-req-build-ht9vz2if\n",
      "  Resolved https://github.com/ageitgey/face_recognition_models to commit e67de717267507d1e9246de95692eb8be736ab61\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: face_recognition in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: qdrant-client in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (1.14.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (80.8.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (1.7.0)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from face_recognition) (8.2.0)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from face_recognition) (19.24.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from qdrant-client) (1.71.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from qdrant-client) (6.30.2)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from qdrant-client) (2.11.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from qdrant-client) (2.4.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (310)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipywidgets) (9.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting networkx>=3.0 (from scikit-image)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\despinxz\\.vscode\\projetos\\tebd_ep\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 7.1/12.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   ---------------- ----------------------- 2/5 [lazy-loader]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   ---------------------------------------- 5/5 [scikit-image]\n",
      "\n",
      "Successfully installed imageio-2.37.0 lazy-loader-0.4 networkx-3.5 scikit-image-0.25.2 tifffile-2025.6.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ageitgey/face_recognition_models 'C:\\Users\\despinxz\\AppData\\Local\\Temp\\pip-req-build-ht9vz2if'\n"
     ]
    }
   ],
   "source": [
    "!powershell pip install \\\n",
    "            face_recognition \\\n",
    "            git+https://github.com/ageitgey/face_recognition_models \\\n",
    "            opencv-python \\\n",
    "            pillow \\\n",
    "            numpy \\\n",
    "            tqdm \\\n",
    "            qdrant-client \\\n",
    "            setuptools \\\n",
    "            ipywidgets \\\n",
    "            matplotlib \\\n",
    "            scikit-learn \\\n",
    "            scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99306496",
   "metadata": {},
   "source": [
    "# Rodar QDrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f59373",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!powershell docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c76196",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287f6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import face_recognition\n",
    "import face_recognition_models\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import Filter, SearchRequest\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sklearn\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb087f",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fedab649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_cliente():\n",
    "    # Conectando ao Qdrant local\n",
    "    client = QdrantClient(\"http://localhost:6333\")\n",
    "    return client\n",
    "\n",
    "def cria_colecao(client, nome_colecao, tamanho_vetor):\n",
    "    # Cria a coleção se não existir\n",
    "    if nome_colecao not in [c.name for c in client.get_collections().collections]:\n",
    "        client.recreate_collection(\n",
    "            collection_name=nome_colecao,\n",
    "            vectors_config=VectorParams(size=tamanho_vetor, distance=Distance.COSINE),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b4306",
   "metadata": {},
   "source": [
    "# Códigos para processar imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427d40d",
   "metadata": {},
   "source": [
    "### Gerar vetor de características por Local Binary Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "890ece4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "def extrai_caracteristicas_lbp(caminho_imagem):\n",
    "    imagem = cv2.imread(caminho_imagem)\n",
    "    # Converte imagem para tons de cinza\n",
    "    imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    metodo = 'uniform'\n",
    "    vetor_final = []\n",
    "\n",
    "    # Para radius 1, 2 e 3\n",
    "    for raio in [1, 2, 3]:\n",
    "        n_pontos = 8 * raio\n",
    "\n",
    "        # Aplica o LBP\n",
    "        lbp = local_binary_pattern(imagem_cinza, n_pontos, raio, metodo)\n",
    "\n",
    "        # Número de bins: n_pontos + 2 para o método 'uniform'\n",
    "        n_bins = n_pontos + 2\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "\n",
    "        # Adiciona o histograma ao vetor final\n",
    "        vetor_final.extend(hist)\n",
    "\n",
    "    id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "    nome_pessoa = caminho_imagem.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Cria estrutura de ponto para inserir na coleção\n",
    "    ponto = PointStruct(\n",
    "            id=id_ponto,\n",
    "            vector=vetor_final,\n",
    "            payload={\"nome\": nome_pessoa, \"arquivo\": caminho_imagem})\n",
    "\n",
    "    return ponto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2fcc54",
   "metadata": {},
   "source": [
    "### Gerar vetor de características por descritores faciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b4423ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def extrai_caracteristicas_landmarks(caminho_imagem):\n",
    "    imagem = cv2.imread(caminho_imagem)\n",
    "    # Converte para RGB (face_recognition usa RGB)\n",
    "    imagem_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detecta landmarks faciais\n",
    "    face_landmarks_list = face_recognition.face_landmarks(imagem_rgb)\n",
    "\n",
    "    # Se não encontrou rosto, retorna vetor vazio\n",
    "    if not face_landmarks_list:\n",
    "        return np.zeros(136)  # 68 pontos * 2 coordenadas (x, y)\n",
    "\n",
    "    # Pegamos os landmarks da primeira face detectada\n",
    "    landmarks = face_landmarks_list[0]\n",
    "\n",
    "    # Reorganiza os pontos na ordem correta (68 pontos padrão)\n",
    "    pontos = []\n",
    "    for key in ['chin', 'left_eyebrow', 'right_eyebrow', 'nose_bridge', 'nose_tip',\n",
    "                'left_eye', 'right_eye', 'top_lip', 'bottom_lip']:\n",
    "        for ponto in landmarks[key]:\n",
    "            pontos.append(ponto)\n",
    "\n",
    "    # Garante que temos sempre 68 pontos\n",
    "    if len(pontos) < 68:\n",
    "        pontos += [(0, 0)] * (68 - len(pontos))\n",
    "\n",
    "    # Normaliza por largura e altura da imagem\n",
    "    h, w = imagem.shape[:2]\n",
    "    vetor = []\n",
    "    for (x, y) in pontos[:68]:\n",
    "        vetor.append(x / w)\n",
    "        vetor.append(y / h)\n",
    "\n",
    "    id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "    nome_pessoa = caminho_imagem.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Cria estrutura de ponto para inserir na coleção\n",
    "    ponto = PointStruct(\n",
    "            id=id_ponto,\n",
    "            vector=vetor,\n",
    "            payload={\"nome\": nome_pessoa, \"arquivo\": caminho_imagem})\n",
    "\n",
    "    return ponto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd428c",
   "metadata": {},
   "source": [
    "### Gerar vetor de características por CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_caracteristicas_cnn(caminho_imagem):\n",
    "    print(caminho_imagem)\n",
    "    imagem = face_recognition.load_image_file(caminho_imagem)\n",
    "    embeddings = face_recognition.face_encodings(imagem)\n",
    "    if not embeddings:\n",
    "        return None  # Nenhum rosto detectado\n",
    "    vetor = embeddings[0]\n",
    "\n",
    "    id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "    nome_pessoa = caminho_imagem.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Cria estrutura de ponto para inserir na coleção\n",
    "    ponto = PointStruct(\n",
    "            id=id_ponto,\n",
    "            vector=vetor,\n",
    "            payload={\"nome\": nome_pessoa, \"arquivo\": caminho_imagem})\n",
    "\n",
    "    return ponto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7a1ab",
   "metadata": {},
   "source": [
    "# Código para selecionar diretórios e separar conjuntos de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb42ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def separa_treino_validacao_lfw(base_dir, proporcao_treino=0.8):\n",
    "    caminhos_treino = []\n",
    "    caminhos_validacao = []\n",
    "\n",
    "    for nome_pessoa in os.listdir(base_dir):\n",
    "        caminho_pessoa = os.path.join(base_dir, nome_pessoa)\n",
    "\n",
    "        if not os.path.isdir(caminho_pessoa):\n",
    "            continue\n",
    "\n",
    "        imagens = [os.path.join(caminho_pessoa, img) for img in os.listdir(caminho_pessoa)\n",
    "                   if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "        total_imagens = len(imagens)\n",
    "\n",
    "        if total_imagens not in [8, 10, 12]:\n",
    "            continue\n",
    "\n",
    "        imagens.sort()  # garantir consistência\n",
    "        random.seed(42)  # garantir que o shuffle será o mesmo em todas as execuções do código\n",
    "        random.shuffle(imagens)\n",
    "\n",
    "        treino, validacao = train_test_split(imagens, train_size=proporcao_treino, shuffle=False)\n",
    "\n",
    "        caminhos_treino.extend(treino)\n",
    "        caminhos_validacao.extend(validacao)\n",
    "\n",
    "    return caminhos_treino, caminhos_validacao\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1237f",
   "metadata": {},
   "source": [
    "# Código para inserir imagem numa coleção "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93656f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserir_imagem(nome_colecao, caminho_imagem, vetor_caracteristicas):\n",
    "    id_ponto = str(uuid.uuid4())    # ID único \n",
    "\n",
    "    nome_pessoa = caminho_imagem.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Cria estrutura de ponto para inserir na coleção\n",
    "    ponto = PointStruct(\n",
    "            id=id_ponto,\n",
    "            vector=vetor_caracteristicas,\n",
    "            payload={\"nome\": nome_pessoa, \"arquivo\": caminho_imagem})\n",
    "    \n",
    "    client.upsert(collection_name=nome_colecao, points=[ponto])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4227b9",
   "metadata": {},
   "source": [
    "# Cria coleções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01d04305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_colecoes():\n",
    "    imagens_treino, imagens_validacao = separa_treino_validacao_lfw(\"lfw_funneled\")\n",
    "\n",
    "    caracteristicas_lbp_treino = []\n",
    "    caracteristicas_landmark_treino = []\n",
    "    caracteristicas_cnn_treino = []\n",
    "\n",
    "    for imagem in tqdm(imagens_treino, desc=\"Processando imagens de treinamento...\"):\n",
    "        caracteristicas_lbp_treino.append(extrai_caracteristicas_lbp(imagem))\n",
    "        caracteristicas_landmark_treino.append(extrai_caracteristicas_landmarks(imagem))\n",
    "        caracteristicas_cnn_treino.append(extrai_caracteristicas_cnn(imagem))\n",
    "\n",
    "    caracteristicas_lbp_validacao = []\n",
    "    caracteristicas_landmark_validacao = []\n",
    "    caracteristicas_cnn_validacao = []\n",
    "\n",
    "    for imagem in tqdm(imagens_validacao, desc=\"Processando imagens de validação...\"):\n",
    "        caracteristicas_lbp_validacao.append(extrai_caracteristicas_lbp(imagem))\n",
    "        caracteristicas_landmark_validacao.append(extrai_caracteristicas_landmarks(imagem))\n",
    "        caracteristicas_cnn_validacao.append(extrai_caracteristicas_cnn(imagem))\n",
    "    \n",
    "    client.upsert(collection_name=lbp_treinamento, points=caracteristicas_lbp_treino)\n",
    "    client.upsert(collection_name=lbp_validacao, points=caracteristicas_lbp_validacao)\n",
    "    client.upsert(collection_name=landmarks_treinamento, points=caracteristicas_landmark_treino)\n",
    "    client.upsert(collection_name=landmarks_validacao, points=caracteristicas_landmark_validacao)\n",
    "    client.upsert(collection_name=cnn_treinamento, points=caracteristicas_cnn_treino)\n",
    "    client.upsert(collection_name=cnn_validacao, points=caracteristicas_cnn_validacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a20020",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5160771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cria_cliente()\n",
    "\n",
    "# Cria coleções para cada método de avaliação\n",
    "cria_colecao(client, \"lbp_treinamento\", 54)\n",
    "cria_colecao(client, \"lbp_validacao\", 54)\n",
    "cria_colecao(client, \"landmarks_treinamento\", 68)\n",
    "cria_colecao(client, \"landmarks_validacao\", 68)\n",
    "cria_colecao(client, \"cnn_treinamento\", 128)\n",
    "cria_colecao(client, \"cnn_validacao\", 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30d4c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   0%|          | 0/408 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0008.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   0%|          | 1/408 [00:00<03:46,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   0%|          | 2/408 [00:01<03:45,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   1%|          | 3/408 [00:01<03:47,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   1%|          | 4/408 [00:02<03:47,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   1%|          | 5/408 [00:02<03:53,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0007.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   1%|▏         | 6/408 [00:03<03:48,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0012.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   2%|▏         | 7/408 [00:03<03:45,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0004.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   2%|▏         | 8/408 [00:04<03:42,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Adrien_Brody\\Adrien_Brody_0005.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   2%|▏         | 9/408 [00:05<03:41,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0004.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   2%|▏         | 10/408 [00:05<03:39,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0005.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   3%|▎         | 11/408 [00:06<03:35,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0007.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   3%|▎         | 12/408 [00:06<03:34,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0008.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   3%|▎         | 13/408 [00:07<04:17,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   3%|▎         | 14/408 [00:08<04:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ali_Naimi\\Ali_Naimi_0006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   4%|▎         | 15/408 [00:08<03:56,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0004.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   4%|▍         | 16/408 [00:09<03:56,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0005.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   4%|▍         | 17/408 [00:09<03:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0007.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   4%|▍         | 18/408 [00:10<03:41,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0008.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   5%|▍         | 19/408 [00:10<03:37,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   5%|▍         | 20/408 [00:11<03:33,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Al_Gore\\Al_Gore_0006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   5%|▌         | 21/408 [00:11<03:32,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0004.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   5%|▌         | 22/408 [00:12<03:31,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0005.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   6%|▌         | 23/408 [00:13<03:28,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0007.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   6%|▌         | 24/408 [00:13<04:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0008.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   6%|▌         | 25/408 [00:14<03:57,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   6%|▋         | 26/408 [00:15<03:51,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Ana_Palacio\\Ana_Palacio_0006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   7%|▋         | 27/408 [00:15<03:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0008.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   7%|▋         | 28/408 [00:16<03:44,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   7%|▋         | 29/408 [00:16<03:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0003.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   7%|▋         | 30/408 [00:17<03:33,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   8%|▊         | 31/408 [00:17<03:29,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0010.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   8%|▊         | 32/408 [00:18<03:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0007.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   8%|▊         | 33/408 [00:18<03:23,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0012.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   8%|▊         | 34/408 [00:19<03:24,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0004.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando imagens de treinamento...:   9%|▊         | 35/408 [00:20<03:34,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfw_funneled\\Anna_Kournikova\\Anna_Kournikova_0005.jpg\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpopular_colecoes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mpopular_colecoes\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      9\u001b[39m     caracteristicas_lbp_treino.append(extrai_caracteristicas_lbp(imagem))\n\u001b[32m     10\u001b[39m     caracteristicas_landmark_treino.append(extrai_caracteristicas_landmarks(imagem))\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     caracteristicas_cnn_treino.append(\u001b[43mextrai_caracteristicas_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     13\u001b[39m caracteristicas_lbp_validacao = []\n\u001b[32m     14\u001b[39m caracteristicas_landmark_validacao = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mextrai_caracteristicas_cnn\u001b[39m\u001b[34m(caminho_imagem)\u001b[39m\n\u001b[32m      3\u001b[39m imagem = face_recognition.load_image_file(caminho_imagem)\n\u001b[32m      4\u001b[39m embeddings = face_recognition.face_encodings(imagem)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vetor = \u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m id_ponto = \u001b[38;5;28mstr\u001b[39m(uuid.uuid4())    \u001b[38;5;66;03m# ID único \u001b[39;00m\n\u001b[32m      9\u001b[39m nome_pessoa = caminho_imagem.split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "popular_colecoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28a40b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
